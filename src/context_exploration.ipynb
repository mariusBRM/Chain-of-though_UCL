{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, StoppingCriteria\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizer import *\n",
    "from generation_processing import *\n",
    "\n",
    "class MySantaCoder(nn.Module):\n",
    "    def __init__(self, list_of_bad_words = ['#'], max_tokens = 128, num_sol = 1):\n",
    "        super(MySantaCoder, self).__init__()\n",
    "        self.checkpoint = \"bigcode/santacoder\"\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.checkpoint, trust_remote_code=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)\n",
    "        self.max_new_tokens = max_tokens\n",
    "        # define the list of bad word that the model should not generate\n",
    "        self.bad_words = self.get_input_ids_as_list(list_of_bad_words)\n",
    "        # define the list of stop words\n",
    "        # self.stop_criteria= self.get_input_ids_as_list(stop_words)\n",
    "        # self.stop_criteria.append(self.tokenizer.eos_token_id)\n",
    "        # self.stopping_criteria = KeyWordsStoppingCriteria(self.stop_criteria)\n",
    "\n",
    "        self.generation_config = GenerationConfig(\n",
    "                bad_words_ids = self.bad_words,\n",
    "                num_beams = num_sol,\n",
    "                num_return_sequences = num_sol,\n",
    "                max_new_tokens = self.max_new_tokens,\n",
    "                # StoppingCriteria = self.stopping_criteria,\n",
    "                eos_token_id=self.model.generation_config.eos_token_id,\n",
    "                bos_token_id=self.model.generation_config.bos_token_id\n",
    "                )\n",
    "\n",
    "    def get_input_ids_as_list(self, list_of_bad_words):\n",
    "        token_list = []\n",
    "        for element in list_of_bad_words:\n",
    "            token_list.append(self.tokenizer.encode(element))\n",
    "        return token_list\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        # input_ids = input_ids.unsqueeze(0)\n",
    "        outputs = self.model.generate(input_ids, self.generation_config)\n",
    "        return outputs\n",
    "\n",
    "    def decode_output(self, encoded_output):\n",
    "        output = self.tokenizer.decode(encoded_output)\n",
    "        return output\n",
    "\n",
    "    def post_generation_processing(self,code):\n",
    "        # split it into list of blocks\n",
    "        list_blocks = re.split('def |class |assert |print ', code)\n",
    "        if 'init' in list_blocks[1]:\n",
    "            fill_word = '\\nclass '\n",
    "        else:\n",
    "            fill_word = '\\ndef '\n",
    "        # keep only the first block\n",
    "        result = list_blocks[0] + fill_word + list_blocks[1]\n",
    "        return result\n",
    "\n",
    "class KeyWordsStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, keywords_ids):\n",
    "        super(KeyWordsStoppingCriteria, self).__init__()\n",
    "        self.keywords_ids = keywords_ids\n",
    "    def __call__(self, input_ids):\n",
    "        if input_ids in self.keywords_ids:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import * \n",
    "\n",
    "converted_mtbp = read_json_line_format('data/MTBP/converted_mtpb.jsonl')\n",
    "mtbp = read_json_line_format('data/MTBP/mtpb.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_name(signature):\n",
    "    # Find the function name using regular expression\n",
    "    match = re.match(r'def ([\\w\\-_%.]+)\\((.*)\\):', signature)\n",
    "    if match:\n",
    "        original_name, parameters = match.groups()\n",
    "        \n",
    "        # Generate a random name with a reasonable length (e.g., length of original name)\n",
    "        random_name = ''.join(random.choice(string.ascii_lowercase) for _ in range(len(original_name)))\n",
    "\n",
    "        # Replace the original name with the random name\n",
    "        new_signature = f'def {random_name}({parameters}):'\n",
    "        return new_signature\n",
    "    else:\n",
    "        print(signature)\n",
    "        # raise ValueError(\"Invalid function signature\")\n",
    "        return signature\n",
    "\n",
    "def custom_dataset_context_investigation(mtbp_converted, mtbp):\n",
    "\n",
    "    # select only features that are interesting\n",
    "    features_name_converted = ['text', 'signature','test_list']\n",
    "    mtbp_converted = mtbp_converted[features_name_converted]\n",
    "    features_name = ['prompts']\n",
    "    mtbp = mtbp[features_name]\n",
    "    \n",
    "    data = pd.concat([mtbp, mtbp_converted], axis=1)\n",
    "\n",
    "    random_names = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        signature = data.iloc[i]['signature']\n",
    "        random_name = generate_random_name(signature)\n",
    "        random_names.append(random_name)\n",
    "\n",
    "    data['random_signatures'] = random_names\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['def', 'if', 'for', 'while']\n",
    "\n",
    "def context_and_contexless_generation(data, model, early_stopping = None):\n",
    "    \"\"\" Generate two types of problems:\n",
    "            1. generate with the appropriate function signature and the context (keep the structural generation cut off)\n",
    "            2. generate with a random function name and without context (keep the structural generation cut off)\n",
    "            3. Keep both generation at each step with a very large cut off function (when finding a new 'def') \n",
    "    \"\"\"\n",
    "    codes_with_context = []\n",
    "    codes_without_context = []\n",
    "\n",
    "    raw_generations_context = []\n",
    "    raw_generations_no_context = []\n",
    "\n",
    "    for j in range(len(data)):\n",
    "        if early_stopping is not None and j > early_stopping:\n",
    "            break\n",
    "\n",
    "        code_with_context = []\n",
    "        code_without_context = []\n",
    "\n",
    "        no_cut_off_no_context = []\n",
    "        no_cut_off_context = []\n",
    "\n",
    "        # start with the signature for the incoming problem\n",
    "        code = data.iloc[j]['signature']\n",
    "        # start with a random name for the incoming problem\n",
    "        code_random = data.iloc[j]['random_signatures']\n",
    "        # initiate the list of prompt to generate\n",
    "        prompts = data.iloc[j]['prompts']\n",
    "        # Iterate over each prompt\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            \n",
    "            # Add the prompt to the previously generated code\n",
    "            input_text_context = code + '\\n\\t' + '#' + prompt\n",
    "            input_text_no_context = code_random +'\\n\\t' + '#' + prompt\n",
    "\n",
    "            # Encode the input text\n",
    "            input_ids_context = model.tokenizer.encode(input_text_context, return_tensors='pt')\n",
    "            input_ids_no_context = model.tokenizer.encode(input_text_no_context, return_tensors='pt')\n",
    "\n",
    "            # Generate the output\n",
    "            output_ids_context = model.forward(input_ids_context)\n",
    "            output_ids_no_context = model.forward(input_ids_no_context)\n",
    "\n",
    "            # Decode the output\n",
    "            output_text_context = model.decode_output(output_ids_context[0])\n",
    "            output_text_no_context = model.decode_output(output_ids_no_context[0])\n",
    "\n",
    "\n",
    "\n",
    "            # Cut off the generated code\n",
    "            code = generation_cut_off(gen_code = output_text_context, stop_words=STOP_WORDS, index_prompt=i)\n",
    "            code_random = generation_cut_off(gen_code = output_text_no_context, stop_words=STOP_WORDS, index_prompt=0)\n",
    "            code_random = remove_context(code_random)\n",
    "\n",
    "            # Keep the generation with a large cut off (new def found)\n",
    "            output_text_context = model.post_generation_processing(output_text_context)\n",
    "            output_text_no_context = model.post_generation_processing(output_text_no_context)\n",
    "\n",
    "            code_with_context.append(code)\n",
    "            code_without_context.append(code_random)\n",
    "\n",
    "            no_cut_off_no_context.append(output_text_no_context)\n",
    "            no_cut_off_context.append(output_text_context)\n",
    "\n",
    "        codes_with_context.append(code_with_context)\n",
    "        codes_without_context.append(code_without_context)\n",
    "\n",
    "        raw_generations_context.append(no_cut_off_context)\n",
    "        raw_generations_no_context.append(no_cut_off_no_context)\n",
    "\n",
    "    return codes_with_context, raw_generations_context, codes_without_context, raw_generations_no_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import *\n",
    "mtbp_converted = read_json_line_format('data/MTBP/converted_mtpb.jsonl')\n",
    "mtbp = read_json_line_format('data/MTBP/mtpb.jsonl')\n",
    "\n",
    "dataset = custom_dataset_context_investigation(mtbp_converted, mtbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "prompt = 1\n",
    "instruction = dataset.iloc[index]['random_signatures'] + '\\n\\t\"\"\"' + dataset.iloc[index]['prompts'][prompt] + '\"\"\"'\n",
    "instruction_comments = '#' + dataset.iloc[index]['prompts'][prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Write a function that takes an integer hours and converts it to seconds.\n"
     ]
    }
   ],
   "source": [
    "print(instruction_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "model = MySantaCoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_ids = model.tokenizer.encode(instruction_comments, return_tensors='pt')\n",
    "output_ids = model.forward(input_ids)\n",
    "output_text = model.decode_output(output_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = output_text + '\\n\\ndef function(test):\\n\\treturn bite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Write a function that takes an integer hours and converts it to seconds.\n",
      "\n",
      "def convert_hours_to_seconds(hours):\n",
      "    return hours * 3600\n",
      "\n",
      "print(convert_hours_to_seconds(1))\n",
      "print(convert_hours_to_seconds(2))\n",
      "print(convert_hours_to_seconds(3))\n",
      "print(convert_hours_to_seconds(4))\n",
      "print(convert_hours_to_seconds(5))\n",
      "print(convert_hours_to_seconds(6))\n",
      "print(convert_hours_to_seconds(7))\n",
      "print(convert_hours_to_seconds(8))\n",
      "\n",
      "\n",
      "def function(test):\n",
      "\treturn bite\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_indices(text, substring):\n",
    "    indices = []\n",
    "    index = text.find(substring)\n",
    "    while index != -1:\n",
    "        indices.append(index)\n",
    "        index = text.find(substring, index + 1)\n",
    "    return indices\n",
    "\n",
    "def starts_with_def(text):\n",
    "    \"\"\" Check if the generated text start with a def or not.\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    found_comment = False\n",
    "\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "\n",
    "        if not found_comment and stripped_line.startswith('#'):\n",
    "            found_comment = True\n",
    "            continue\n",
    "\n",
    "        if found_comment and stripped_line:\n",
    "            return stripped_line.startswith('def')\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cut_off_generated_text(text):\n",
    "    # Finding the index of the pattern '\\n\\nprint('\n",
    "    index_print = text.find('\\n\\nprint(')\n",
    "    # Finding the index of the pattern '\\n\\ndef'\n",
    "    index_def = text.find('\\n\\ndef')\n",
    "    startwith_def = starts_with_def(text)\n",
    "    indexes_def = find_all_indices(text, '\\n\\ndef')\n",
    "    # Finding the minimum index among the two patterns (if found)\n",
    "    index = -1\n",
    "    if index_print != -1 and index_def != -1:\n",
    "        # there are both 'def's and 'print()'s within the text\n",
    "        if startwith_def:\n",
    "            if len(indexes_def) > 1:\n",
    "                index_def = indexes_def[1]\n",
    "            else:\n",
    "                index_def = np.inf\n",
    "        index = min(index_print, index_def)\n",
    "    elif index_print != -1:\n",
    "        index = index_print\n",
    "    elif index_def != -1:\n",
    "        index = index_def\n",
    "\n",
    "    # If any pattern is found, slicing the text accordingly\n",
    "    if index != -1:\n",
    "        return text[:index]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef convert_hours_to_seconds(hours):\\n    return hours * 3600\\n\\nprint(convert_hours_to_seconds(1))\\nprint(convert_hours_to_seconds(2))\\nprint(convert_hours_to_seconds(3))\\nprint(convert_hours_to_seconds(4))\\nprint(convert_hours_to_seconds(5))\\nprint(convert_hours_to_seconds(6))\\nprint(convert_hours_to_seconds(7))\\nprint(convert_hours_to_seconds(8))\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text[73:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Write a function that takes an integer hours and converts it to seconds.\n",
      "\n",
      "def convert_hours_to_seconds(hours):\n",
      "    return hours * 3600\n"
     ]
    }
   ],
   "source": [
    "print(cut_off_generated_text(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MySantaCoder()\n",
    "codes_with_context, codes_without_context, codes_without_context, raw_generations_no_context = context_and_contexless_generation(data=dataset, model=model, early_stopping=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def normalize_integer_list(numbers):\\n\\t#Define a list of integers named \"numbers\" with the values {numbers}.\\n\\tnumbers = [int(x) for x in numbers]',\n",
       " 'def normalize_integer_list(numbers):\\n\\t#Calculate the sum of the elements in variable \"numbers\" and store the result to variable \"total\".\\n\\ttotal = sum(numbers)',\n",
       " 'def normalize_integer_list(numbers):\\n\\t#Divide each element of the list by the total and multiply by 100, store the result to variable \"normalized\".\\n\\tnormalized = []',\n",
       " 'def normalize_integer_list(numbers):\\n\\t#Convert each element in variable \"normalized\" into a formatted string with single decimal point and store the result into \"formatted\".\\n\\tformatted = []',\n",
       " 'def normalize_integer_list(numbers):\\n\\t#Print the variable \"formatted\".\\n\\tformatted = []']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_with_context[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def wicupvsftvndphmdqgwdyw(numbers):\\n\\tnumbers = [int(x) for x in numbers]',\n",
       " 'def wicupvsftvndphmdqgwdyw(numbers):\\n\\ttotal = 0',\n",
       " 'def wicupvsftvndphmdqgwdyw(numbers):\\n\\tnormalized = []',\n",
       " 'def wicupvsftvndphmdqgwdyw(numbers):\\n\\tformatted = \"\"',\n",
       " 'def wicupvsftvndphmdqgwdyw(numbers):\\n\\tformatted = \"\"']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_without_context[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
