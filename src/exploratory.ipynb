{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MTPB Data: step-by-step instructions --> incremental code generation </h1>\n",
    "\n",
    "<p>\n",
    "generate code using MTPB's \"prompt\" instructions, alternating between prompts and code as shown below:\n",
    "\n",
    "Input: prompt1\n",
    "Output: code1\n",
    "\n",
    "Input: code1 + prompt2\n",
    "Output: code2\n",
    "\n",
    "Input: code1 + code2 + prompt3\n",
    "Output: code3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def read_json_line_format(path_to_file):\n",
    "    \"\"\"\n",
    "        Read a JSON Lines format and store it into a dataframe.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path_to_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "    return df\n",
    "\n",
    "mtbp_path = 'data/mtpb.jsonl'\n",
    "mtbp_data = read_json_line_format(mtbp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(input_list):\n",
    "    \"\"\"\n",
    "        Get the list of unique input keys and list it (comma separated).\n",
    "    \"\"\"\n",
    "    keys = set()\n",
    "    for d in input_list:\n",
    "        keys.update(d.keys())\n",
    "    keys = sorted(list(keys))  # sort keys for consistent output\n",
    "    return ','.join(keys)\n",
    "\n",
    "def processing_name(name):\n",
    "     #TODO: do the name processing\n",
    "    return None\n",
    "\n",
    "def create_signature_for_function(data):\n",
    "\n",
    "    # initiate a list of signature\n",
    "    signatures = []\n",
    "    # loop over all the rows\n",
    "    for i in range(len(data)):\n",
    "        # extract the name of the according problem\n",
    "        name = data.iloc[i]['name']\n",
    "        # process the name\n",
    "        name = processing_name(name)\n",
    "        # get the name of the input\n",
    "        # create the function signature architecture\n",
    "        signature = f'def '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a1': 3, 'a2': 5, 'a3': 0, 'a4': 4},\n",
       " {'a1': 5, 'a2': 3, 'a3': 0, 'a4': 9},\n",
       " {'a1': 9, 'a2': 3, 'a3': 0, 'a4': 2},\n",
       " {'a1': 2, 'a2': 4, 'a3': 0, 'a4': 7},\n",
       " {'a1': 2, 'a2': 4, 'a3': 4, 'a4': 7}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtbp_data.iloc[6]['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompts           [Initialize a list of integers with {a1} and a...\n",
       "inputs            [{'a1': '[0,1,2,3]', 'a2': '4'}, {'a1': '[1, 1...\n",
       "outputs                    [[1, 3], [1, 2], [0, 3], [2, 3], [2, 3]]\n",
       "max_gen_length                                                128.0\n",
       "category                                                  algorithm\n",
       "name                                                        Two-sum\n",
       "description       Implement the two-sum problem on a given input...\n",
       "id                                                               19\n",
       "Name: 18, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtbp_data.iloc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Create a function encrypt that takes a string as an argument and returns a string encrypted with the alphabet being rotated. The alphabet should be rotated in a manner such that the letters shift down by two places. For example: encrypt('hi') returns 'jk', encrypt('asdfghjkl') returns 'cufhijlmn', encrypt('gf') returns 'ih'.\",\n",
       " 'Create a function decrypt that decodes the encrypted string from encrypt() back into the original text.',\n",
       " 'Assign \"{a1}\" to a variable named \"original_text\".',\n",
       " \"Call the function encrypt with original_text as argument and assign the result to a variable named 'encrypted_text'.\",\n",
       " \"Call the function decrypt with encrypted_text as argument and assign the result to a variable named 'restored_text'.\",\n",
       " 'Create a list named \"my_result\" containing restored_text and encrypted_text as elements.',\n",
       " 'Print the list.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtbp_data.iloc[14]['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_bracket_content(text):\n",
    "    pattern = \"{(.*?)}\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match is not None:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def managing_prompts_with_input(prompts, input):\n",
    "    \"\"\"\n",
    "        This function gives an example of the architecture of the input\n",
    "    \"\"\"\n",
    "    # we will simply add an example of the architecture of the first input. eg {input} for example : 'input' = [1,2,3]\n",
    "    processed_prompts = []\n",
    "    # Look for the prompt to change\n",
    "    for prompt in prompts:\n",
    "        # extract the input key to replace with the for example\n",
    "        input_key = extract_bracket_content(prompt)\n",
    "        if input_key is None:\n",
    "            processed_prompts.append(prompt)\n",
    "        else:\n",
    "            added_prompt = '{' + input_key + '}' + f' for example : {input_key} = {input[input_key]} '\n",
    "            processed_prompt = prompt.replace(input_key,added_prompt)\n",
    "\n",
    "    return processed_prompt\n",
    "\n",
    "prompts = mtbp_data.iloc[0]['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Assign the string \"{A}\" to a variable named \"my_string\".',\n",
       " 'Lowercase the given string \"my_string\".',\n",
       " 'Assign the distinct characters of the string to a variable named \"chars\".',\n",
       " 'Sort these characters in alphabetical order.',\n",
       " 'Print the resulting list of characters.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from santaC import *\n",
    "\n",
    "\n",
    "def generating_step_by_step_with_context(model, data):\n",
    "    # Starting with an empty piece of code\n",
    "    code = ''\n",
    "\n",
    "    for j in range(len(data)):\n",
    "        if j > 2 : \n",
    "            break\n",
    "        else:\n",
    "            prompts = data.iloc[j]['prompts']\n",
    "            # Iterate over each prompt\n",
    "            for i, prompt in enumerate(prompts):\n",
    "                # show what prompts is currently beeing used\n",
    "                print(f\"Prompt {i+1}: {prompt}\")\n",
    "\n",
    "                # Add the prompt to the previously generated code\n",
    "                input_text = code + '\\n' + '#' + prompt\n",
    "\n",
    "                # Encode the input text\n",
    "                input_ids = model.tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "                # Generate the output\n",
    "                output_ids = model.forward(input_ids)\n",
    "\n",
    "                # Decode the output\n",
    "                output_text = model.decode_output(output_ids[0])\n",
    "\n",
    "                # Process output\n",
    "                \n",
    "                # Extract the newly generated code\n",
    "                new_code = output_text[len(input_text):].strip()\n",
    "\n",
    "                # Append the newly generated code to the existing code\n",
    "                code += '\\n' + new_code\n",
    "\n",
    "                # print(f\"Code after step {i+1}:\\n{code}\\n{'-'*50}\")\n",
    "\n",
    "        print(\"Final generated code:\\n\", code)\n",
    "\n",
    "model = MySantaCoder('GrdS', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_step_by_step_with_context(model, mtbp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySantaCoder('GrdS', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 128 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generated_code_signature = 'def assign(A):\\n' \n",
    "example_of_prompt = '\\t# Assign the string \"{A}\" to a variable named \"my_string\".'\n",
    "code_to_prompt = generated_code_signature + example_of_prompt\n",
    "input_ids = model.tokenizer.encode(code_to_prompt, return_tensors='pt')\n",
    "\n",
    "# Generate the output\n",
    "output_ids = model.forward(input_ids)\n",
    "\n",
    "# Decode the output\n",
    "output_text = model.decode_output(output_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def assign(A):\n",
      "\t# Assign the string \"{A}\" to a variable named \"my_string\".\n",
      "\tmy_string = A\n",
      "\t# Print the value of my_string.\n",
      "\tprint(my_string)\n",
      "\n",
      "# Call the function assign.\n",
      "assign(\"Hello\")\n",
      "\n",
      "# Print the value of my_string.\n",
      "print(my_string)\n",
      "\n",
      "# Print the value of my_string.\n",
      "print(my_string)\n",
      "\n",
      "# Print the value of my_string.\n",
      "print(my_string)\n",
      "\n",
      "# Print the value of my_string.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
