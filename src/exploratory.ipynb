{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MTPB Data: step-by-step instructions --> incremental code generation </h1>\n",
    "\n",
    "<p>\n",
    "generate code using MTPB's \"prompt\" instructions, alternating between prompts and code as shown below:\n",
    "\n",
    "Input: prompt1\n",
    "Output: code1\n",
    "\n",
    "Input: code1 + prompt2\n",
    "Output: code2\n",
    "\n",
    "Input: code1 + code2 + prompt3\n",
    "Output: code3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def read_json_line_format(path_to_file):\n",
    "    \"\"\"\n",
    "        Read a JSON Lines format and store it into a dataframe.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path_to_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "    return df\n",
    "########################### Unused yet ###############################\n",
    "def extract_bracket_content(text):\n",
    "    pattern = \"{(.*?)}\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match is not None:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def managing_prompts_with_input(prompts, input):\n",
    "    \"\"\"\n",
    "        This function gives an example of the architecture of the input\n",
    "    \"\"\"\n",
    "    # we will simply add an example of the architecture of the first input. eg {input} for example : 'input' = [1,2,3]\n",
    "    processed_prompts = []\n",
    "    # Look for the prompt to change\n",
    "    for prompt in prompts:\n",
    "        # extract the input key to replace with the for example\n",
    "        input_key = extract_bracket_content(prompt)\n",
    "        if input_key is None:\n",
    "            processed_prompts.append(prompt)\n",
    "        else:\n",
    "            added_prompt = '{' + input_key + '}' + f' for example : {input_key} = {input[input_key]} '\n",
    "            processed_prompt = prompt.replace(input_key,added_prompt)\n",
    "\n",
    "    return processed_prompt\n",
    "#######################################################################\n",
    "\n",
    "def get_keys(input_list):\n",
    "    \"\"\"Get the list of unique input keys and list it (comma separated).\n",
    "    \"\"\"\n",
    "    keys = set()\n",
    "    for d in input_list:\n",
    "        keys.update(d.keys())\n",
    "    keys = sorted(list(keys))  # sort keys for consistent output\n",
    "    return ','.join(keys)\n",
    "\n",
    "def processing_name(name):\n",
    "    \"\"\"Processing the name of the problem to match the syntax of a function\n",
    "    \"\"\"\n",
    "    name = name.lower()  # convert to lowercase\n",
    "    name = re.sub('[^a-z0-9 ]', '', name)  # remove any non-alphanumeric characters (except spaces)\n",
    "    name = re.sub(' ', '_', name)  # replace spaces with underscores\n",
    "    return name\n",
    "\n",
    "def create_signature_for_function(data):\n",
    "    \"\"\"Create the function signature for each problem.\n",
    "    \"\"\"\n",
    "    # initiate a list of signature\n",
    "    signatures = []\n",
    "    # loop over all the rows\n",
    "    for i in range(len(data)):\n",
    "        # extract the name of the according problem\n",
    "        name = data.iloc[i]['name']\n",
    "        # process the name\n",
    "        name = processing_name(name)\n",
    "        # get the input\n",
    "        inputs = data.iloc[i]['inputs']\n",
    "        # extract the name\n",
    "        input_keys = get_keys(inputs)\n",
    "        # create the function signature architecture\n",
    "        signature = f'def {name}({input_keys}):'\n",
    "        # adding the signature to the list\n",
    "        signatures.append(signature)\n",
    "    \n",
    "    data['signature'] = signatures\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "from santaC import *\n",
    "\n",
    "max_token_to_generate = 128\n",
    "model = MySantaCoder('SmplM', max_token_to_generate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mtbp_path = 'data/mtpb.jsonl'\n",
    "converted_mtbp_data = 'data/converted_mtpb.jsonl'\n",
    "mtbp_data = read_json_line_format(mtbp_path)\n",
    "converted_mtbp_data = read_json_line_format(converted_mtbp_data)\n",
    "\n",
    "# mtbp_data = create_signature_for_function(mtbp_data)\n",
    "mtbp_data['signature'] = converted_mtbp_data['signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Assign the string \"{A}\" to a variable named \"my_string\".',\n",
       " 'Lowercase the given string \"my_string\".',\n",
       " 'Assign the distinct characters of the string to a variable named \"chars\".',\n",
       " 'Sort these characters in alphabetical order.',\n",
       " 'Print the resulting list of characters.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtbp_data.iloc[0]['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_code_until_after_first_comment(code):\n",
    "    # Split the code into lines\n",
    "    code_lines = code.split('\\n')\n",
    "    # Initialize a list to store the output lines\n",
    "    output_lines = []\n",
    "    # Initialize a variable to keep track if a comment has been found\n",
    "    comment_found = False\n",
    "    # Loop over the lines\n",
    "    for line in code_lines:\n",
    "        # Add the line to the output\n",
    "        output_lines.append(line)\n",
    "        # If the line starts with a tab followed by a hash and a comment hasn't been found before,\n",
    "        # mark that a comment has been found\n",
    "        if line.startswith('\\t#') and not comment_found:\n",
    "            comment_found = True\n",
    "        # If a comment has been found and the current line does not start with a comment, stop adding lines to the output\n",
    "        elif comment_found and not line.startswith('\\t#'):\n",
    "            # need to make a function that keep the structure\n",
    "            break\n",
    "    # Join the output lines back together with newlines and return the result\n",
    "    return '\\n'.join(output_lines)\n",
    "\n",
    "def get_code_for_prompt_old(code_text, prompt_index):\n",
    "    lines = code_text.split('\\n')\n",
    "    prompt_count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('#'):  # we have a new prompt\n",
    "            if prompt_count == prompt_index:  # we have reached the desired prompt\n",
    "                break\n",
    "            prompt_count += 1\n",
    "    return '\\n'.join(lines[:i+2])  # include the next line after the prompt\n",
    "\n",
    "def remove_context(code):\n",
    "    \"\"\"remove all lines starting with '\\t#' \n",
    "    \"\"\"\n",
    "    lines = code.split('\\n')\n",
    "    # keep only lines that don't start with '\\t#'\n",
    "    lines = [line for line in lines if not line.startswith('\\t#')]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# we want to build a function that : \n",
    "#     - stop generates after the instruction is full filled after the last prompt :\n",
    "#         * only line after is kept ( current naive approach )\n",
    "#         * the rest is kept if the first line contains : \n",
    "#             - an 'if' statement is found : keep all the if structure until new indentation\n",
    "#                 ex :  \\n\\tif (...):\\n\\t\\t#code\\n\\t#after {all the 'after' needs to be deleted}\n",
    "#             - a 'def' is found : keep all the def function until the 'return' associated with this function\n",
    "#             - a 'for' loop is found : keep all the structure of the 'for' loop ( the same way as the 'if' statement works )\n",
    "#             - a 'while' loop is found : keep all the structure of the 'while' loop ( the same way as the 'if and the 'for')\n",
    "#     - when find a module 'import' place it before the first function signature it finds ( might need to be tricky )\n",
    "#         - either doing afterward meaning once everything has been generated\n",
    "#         - doing it before the generation starts\n",
    "\n",
    "stop_words = ['def', 'if', 'for', 'while']\n",
    "\n",
    "def check_if_start_with(stop_words, line):\n",
    "    # check if a string begins with some stop words\n",
    "    for word in stop_words:\n",
    "        if line.strip().startswith(word) and count_indentation(line) == 1:\n",
    "            return True   \n",
    "    return False\n",
    "\n",
    "def count_indentation(line):\n",
    "    # count the number of indentation in a line\n",
    "    count = 0\n",
    "    for char in line:\n",
    "        if char == '\\t':\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    return count\n",
    "\n",
    "def identify_what_step_instruction(lines, index_prompt, keep_context):\n",
    "    \"\"\"\n",
    "        function that spot the line at wich the current step is being considered ( the index of the last prompt )\n",
    "\n",
    "        Input:\n",
    "            lines\n",
    "        Output:\n",
    "            index of the line where the generation starts\n",
    "    \"\"\"\n",
    "    # initialise the promp cursor\n",
    "    prompt_count = 0\n",
    "    # initialise the index at which the generation has started\n",
    "    index_to_start = 0\n",
    "    # iterate through the lines\n",
    "    for i,line in enumerate(lines):\n",
    "        # if the context as been kept (we count the number of comments generated)\n",
    "        if keep_context:\n",
    "            # we need to know according to what prompt we are trying to generate code\n",
    "            if line.strip().startswith('#') and count_indentation(line) == 1:  # we have a new prompt\n",
    "                if prompt_count == index_prompt:  # we have reached the desired prompt\n",
    "                    index_to_start = i\n",
    "                prompt_count += 1\n",
    "        else:\n",
    "            # the first prompt encountered is the actual step\n",
    "            if line.strip().startswith('#'):\n",
    "                index_to_start = i\n",
    "                   \n",
    "    return index_to_start\n",
    "\n",
    "def identify_chunks_of_code(list_lines, stop_words):\n",
    "    \"\"\"\n",
    "        Truncate the chunk of code that is to be generated with the current step\n",
    "\n",
    "        Input:\n",
    "            list_lines: the list of lines after the current step\n",
    "    \"\"\"\n",
    "    # initialise the level of indentation of the current chunks of code and the number of line within it\n",
    "    indentation_reference = 0\n",
    "    nb_line_of_code = 1\n",
    "    # initialise the chunk of codes that needs to be saved\n",
    "    chunk_of_code = []\n",
    "    try:\n",
    "        # first line is the line right after the last\n",
    "        first_line = list_lines[0]\n",
    "        \n",
    "        if check_if_start_with(stop_words, first_line):\n",
    "            indentation_reference = count_indentation(first_line) + 1 # number of '\\t' found in the line ( needs to count it )\n",
    "            # keep track of the structure and check the indentation level\n",
    "            for _, step_in in enumerate(list_lines[1:]): \n",
    "                # check the indentation level and as soon as line looses their indentation cut off\n",
    "                indentation_level = count_indentation(step_in)\n",
    "                if indentation_level >= indentation_reference:\n",
    "                    nb_line_of_code+=1\n",
    "                else:\n",
    "                    break\n",
    "            # append all of the lines\n",
    "            for i in range(nb_line_of_code):\n",
    "                chunk_of_code.append(list_lines[i])         \n",
    "        else:\n",
    "            chunk_of_code.append(list_lines[0])\n",
    "    except NameError:\n",
    "        print(f'{NameError} for this one...')\n",
    "\n",
    "    return chunk_of_code\n",
    "\n",
    "def generation_cut_off(gen_code, stop_words, keep_context = False, index_prompt = None):\n",
    "    \"\"\"\n",
    "        A function that cut off the code which let only the instructed code that was generated\n",
    "\n",
    "        Input:\n",
    "            gen_code: a text of generated code\n",
    "            stop_words: a list of stop words\n",
    "        Output:\n",
    "            processed_gen_code: the processed code\n",
    "    \"\"\"\n",
    "    \n",
    "    # First we have to split the code as a list of lines\n",
    "    lines = gen_code.split('\\n')\n",
    "\n",
    "    # we identify the last prompts we are interested in. \n",
    "    index_last_prompt = identify_what_step_instruction(lines, index_prompt, keep_context)\n",
    "\n",
    "    # we then keep only the code generated to come\n",
    "    begining = index_last_prompt + 1\n",
    "    steps = lines[begining:]\n",
    "    \n",
    "    # we extract the chunks of codes that is generated out for the last prompt\n",
    "    chunks_of_code = identify_chunks_of_code(steps, stop_words)\n",
    "\n",
    "    # we need to keep the code previously generated and the last piece of code that has been generated\n",
    "    codes = lines[:index_last_prompt] + chunks_of_code\n",
    "            \n",
    "    return '\\n'.join(codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from santaC import *\n",
    "\n",
    "def generating_step_by_step(model, data, stop_words, keep_context = True, early_stopping = None):\n",
    "    \"\"\"Generating code step by step \n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    for j in range(len(data)):\n",
    "        if early_stopping is not None and j > early_stopping:\n",
    "            break\n",
    "        # start with the signature for the incoming problem\n",
    "        code = data.iloc[j]['signature']\n",
    "        # initiate the list of prompt to generate\n",
    "        prompts = data.iloc[j]['prompts']\n",
    "        # Iterate over each prompt\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            # Add the prompt to the previously generated code\n",
    "            input_text = code + '\\n\\t' + '#' + prompt\n",
    "            \n",
    "            # Encode the input text\n",
    "            input_ids = model.tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "            # Generate the output\n",
    "            output_ids = model.forward(input_ids)\n",
    "\n",
    "            # Decode the output\n",
    "            output_text = model.decode_output(output_ids[0])\n",
    "\n",
    "            code = generation_cut_off(output_text, stop_words, keep_context, i)\n",
    "\n",
    "            # keep only the last code generated after the output\n",
    "            if keep_context==False:\n",
    "                # remove context if set to False\n",
    "                code = remove_context(code)\n",
    "\n",
    "        # print(\"Final generated code:\\n\", code)\n",
    "        codes.append(code)\n",
    "\n",
    "    return codes\n",
    "    \n",
    "\n",
    "\n",
    "codes = generating_step_by_step(model=model, data=mtbp_data, stop_words=stop_words, keep_context = True, early_stopping=2)\n",
    "#mtbp_data['gen_code'] = codes\n",
    "#mtbp_data.to_csv('data/step_by_step/structural_mtbp_with_context_Sampling.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the generation cut off function to see if it works properly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 'def count_zeros(ars):\\n\\t# Initialize counter to zero\\n\\tcounter = 0\\n\\t# Loop over each element in the list\\n\\tfor i in ars:\\n\\t\\t# Increment counter if the element is zero\\n\\t\\tif i == 0:\\n\\t\\t\\tcounter += 1\\n\\t# Return the count of zeros\\n\\treturn counter'\n",
    "test2 = 'def first_element(ars):\\n\\t# Assign the first element of the list to a variable\\n\\tfirst = ars[0]\\n\\t# Return the first element\\n\\treturn first'\n",
    "test3 = 'def sum_while(ars):\\n\\t# Initialize variables\\n\\ttotal = 0\\n\\ti = 0\\n\\t# While loop until reaching the end of the list\\n\\twhile i < len(ars):\\n\\t\\t# Add current value to total\\n\\t\\ttotal += ars[i]\\n\\t\\t# Increment the index\\n\\t\\ti += 1\\n\\t# Return the total sum\\n\\treturn total'\n",
    "test4 = 'def filter_negatives(ars):\\n\\t# Initialize an empty list for positive numbers\\n\\tpositives = []\\n\\t# Loop over each element in the list\\n\\tfor num in ars:\\n\\t\\t# Add number to the list if it\\'s non-negative\\n\\t\\tif num >= 0:\\n\\t\\t\\tpositives.append(num)\\n\\t# Return the list of non-negative numbers\\n\\treturn positives'\n",
    "test5 = 'def flatten_list(ars):\\n\\t# Initialize an empty list for the result\\n\\tflattened = []\\n\\t# Loop over each element in the list\\n\\tfor sublist in ars:\\n\\t\\t# Loop over each element in the sublist\\n\\t\\tfor item in sublist:\\n\\t\\t\\t# Add item to the flattened list\\n\\t\\t\\tflattened.append(item)\\n\\t# Return the flattened list\\n\\treturn flattened'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = generation_cut_off(test5, stop_words, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def flatten_list(ars):\n",
      "\t# Initialize an empty list for the result\n",
      "\tflattened = []\n",
      "\t# Loop over each element in the list\n",
      "\tfor sublist in ars:\n",
      "\t\t# Loop over each element in the sublist\n",
      "\t\tfor item in sublist:\n",
      "\t\t\t# Add item to the flattened list\n",
      "\t\t\tflattened.append(item)\n",
      "\t# Return the flattened list\n",
      "\treturn flattened\n",
      "=============\n",
      "def flatten_list(ars):\n",
      "\t# Initialize an empty list for the result\n",
      "\tflattened = []\n",
      "\t# Loop over each element in the list\n",
      "\tfor sublist in ars:\n",
      "\t\t# Loop over each element in the sublist\n",
      "\t\tfor item in sublist:\n",
      "\t\t\t# Add item to the flattened list\n",
      "\t\t\tflattened.append(item)\n",
      "\treturn flattened\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "print(test5)\n",
    "print('=============')\n",
    "print(codes)\n",
    "print('==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mtbp_without = pd.read_csv('data/step_by_step/line_by_line_without_context_Sampling.csv')\n",
    "mtbp_with = pd.read_csv('data/step_by_step/line_by_line_with_context_Sampling.csv')\n",
    "coverted_data = read_json_line_format('data/converted_mtpb.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def invert_dict(a1,a2,a3):\\r\\npass'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverted_data.iloc[10]['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def function(a):\n",
      "\tmy_string=a\n",
      "\tprint(my_string)\n",
      "\tprint(my_string, my_string)\n",
      "\t#return the string\n",
      "\treturn my_string\n"
     ]
    }
   ],
   "source": [
    "trys = 'def function(a):\\n\\t#Assign the value a to \"my_string\"\\n\\tmy_string=a\\n\\t#print the value ones\\n\\tprint(my_string)\\n\\t#print the value twice\\n\\tprint(my_string, my_string)\\n\\t#return the string\\n\\treturn my_string'\n",
    "trys_wocon = 'def function(a):\\n\\tmy_string=a\\n\\tprint(my_string)\\n\\tprint(my_string, my_string)\\n\\t#return the string\\n\\treturn my_string'\n",
    "print(trys_wocon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generation_cut_off(gen_code, stop_words, keep_context = False, index_prompt = None):\n",
    "#     \"\"\"\n",
    "#         A function that cut off the code which let only the instructed code that was generated\n",
    "\n",
    "#         Input:\n",
    "#             gen_code: a text of generated code\n",
    "#             stop_words: a list of stop words\n",
    "#         Output:\n",
    "#             processed_gen_code: the processed code\n",
    "#     \"\"\"\n",
    "#     codes = []\n",
    "#     begining = 0\n",
    "#     chunks_of_code = 0\n",
    "#     prompt_count = 0\n",
    "#     # First we have to split the code as a list of lines\n",
    "#     lines = gen_code.split('\\n')\n",
    "#     # output_lines = []\n",
    "#     # We go through each line except for the first one which is 'def my_signature_function()'\n",
    "#     for i,line in enumerate(lines):\n",
    "#         # if the context as been kept \n",
    "#         if keep_context:\n",
    "#             # we need to know according to what prompt we are trying to generate code\n",
    "#             if line.strip().startswith('#'):  # we have a new prompt\n",
    "#                 if prompt_count == index_prompt:  # we have reached the desired prompt\n",
    "#                     # we need to keep the step that is generated\n",
    "#                     # the first line of code after the last step to generate\n",
    "#                     begining = i+1\n",
    "#                     steps = lines[begining:]\n",
    "#                     # if it begins with any stopwords\n",
    "#                     if check_if_start_with(stop_words, steps[0]):\n",
    "#                         indentation_reference = count_indentation(steps[0]) + 1 # number of '\\t' found in the line ( needs to count it )\n",
    "#                         for k, step_in in enumerate(steps[1:]): \n",
    "#                             # check the indentation level and as soon as line looses their indentation cut off\n",
    "#                             indentation_level = count_indentation(step_in)\n",
    "#                             if indentation_level == indentation_reference:\n",
    "#                                 chunks_of_code+=1\n",
    "#                             else:\n",
    "#                                 break                                     \n",
    "#                 prompt_count += 1\n",
    "#         else:\n",
    "#             # the first prompt encountered is the actual step\n",
    "            \n",
    "#             # then follow up with the structure we need to keep\n",
    "            \n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['def', 'if', 'for', 'while']\n",
    "\n",
    "def check_if_start_with(stop_words, line):\n",
    "    # check if a string begins with some stop words\n",
    "    for word in stop_words:\n",
    "        if line.strip().startwith(word):\n",
    "            return True   \n",
    "    return False\n",
    "\n",
    "def count_indentation(line):\n",
    "    # count the number of indentation in a line\n",
    "    count = 0\n",
    "    for char in line:\n",
    "        if char == '\\t':\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    return count\n",
    "\n",
    "def identify_what_step_instruction(lines, index_prompt, keep_context):\n",
    "    \"\"\"\n",
    "        function that spot the line at wich the current step is being considered ( the index of the last prompt )\n",
    "\n",
    "        Input:\n",
    "            lines\n",
    "        Output:\n",
    "            index of the line where the generation starts\n",
    "    \"\"\"\n",
    "    # initialise the promp cursor\n",
    "    prompt_count = 0\n",
    "    # initialise the index at which the generation has started\n",
    "    index_to_start = 0\n",
    "    # iterate through the lines\n",
    "    for i,line in enumerate(lines):\n",
    "        # if the context as been kept (we count the number of comments generated)\n",
    "        if keep_context:\n",
    "            # we need to know according to what prompt we are trying to generate code\n",
    "            if line.strip().startswith('#'):  # we have a new prompt\n",
    "                if prompt_count == index_prompt:  # we have reached the desired prompt\n",
    "                    index_to_start = i\n",
    "                prompt_count += 1\n",
    "        else:\n",
    "            # the first prompt encountered is the actual step\n",
    "            if line.strip().startswith('#'):\n",
    "                index_to_start = i\n",
    "                   \n",
    "    return index_to_start\n",
    "\n",
    "def identify_chunks_of_code(list_lines, stop_words):\n",
    "    \"\"\"\n",
    "        Truncate the chunk of code that is to be generated with the current step\n",
    "\n",
    "        Input:\n",
    "            list_lines: the list of lines after the current step\n",
    "    \"\"\"\n",
    "    # initialise the level of indentation of the current chunks of code and the number of line within it\n",
    "    indentation_reference = 0\n",
    "    nb_line_of_code = 1\n",
    "    # initialise the chunk of codes that needs to be saved\n",
    "    chunk_of_code = []\n",
    "\n",
    "    if check_if_start_with(stop_words, list_lines[0]):\n",
    "        indentation_reference = count_indentation(list_lines[0]) + 1 # number of '\\t' found in the line ( needs to count it )\n",
    "        # keep track of the structure and check the indentation level\n",
    "        for _, step_in in enumerate(list_lines[1:]): \n",
    "            # check the indentation level and as soon as line looses their indentation cut off\n",
    "            indentation_level = count_indentation(step_in)\n",
    "            if indentation_level == indentation_reference:\n",
    "                nb_line_of_code+=1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        for i in range(nb_line_of_code):\n",
    "            chunk_of_code.append(list_lines[i])         \n",
    "    else:\n",
    "        chunk_of_code.append(list_lines[0])\n",
    "\n",
    "    return chunk_of_code\n",
    "\n",
    "def generation_cut_off(gen_code, stop_words, keep_context = False, index_prompt = None):\n",
    "    \"\"\"\n",
    "        A function that cut off the code which let only the instructed code that was generated\n",
    "\n",
    "        Input:\n",
    "            gen_code: a text of generated code\n",
    "            stop_words: a list of stop words\n",
    "        Output:\n",
    "            processed_gen_code: the processed code\n",
    "    \"\"\"\n",
    "    \n",
    "    # First we have to split the code as a list of lines\n",
    "    lines = gen_code.split('\\n')\n",
    "\n",
    "    # we identify the last prompts we are interested in. \n",
    "    index_last_prompt = identify_what_step_instruction(lines, index_prompt, keep_context)\n",
    "\n",
    "    # we then keep only the code generated to come\n",
    "    begining = index_last_prompt+1\n",
    "    steps = lines[begining:]\n",
    "\n",
    "    # we extract the chunks of codes that is generated out for the last prompt\n",
    "    chunks_of_code = identify_chunks_of_code(steps, stop_words)\n",
    "\n",
    "    # we need to keep the code previously generated and the last piece of code that has been generated\n",
    "    codes = lines[:index_last_prompt] + chunks_of_code\n",
    "            \n",
    "    return '\\n'.join(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "from santaC import *\n",
    "\n",
    "model = MySantaCoder(generation_method = 'SmplM', num_sol=10)\n",
    "\n",
    "data = pd.read_csv('data/mbpp_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ['\\tfor i in range(k):', '\\tvalue+=i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[0].strip().startswith('for')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploration of the outputs<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lbl_c_mtbp = pd.read_csv(\"data/step_by_step/line_by_line_with_context_Sampling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comment_ratio(func_code):\n",
    "    # Split the code into lines\n",
    "    lines = func_code.strip().split('\\n')\n",
    "    # Initialize counters\n",
    "    code_lines = 0\n",
    "    comment_lines = 0\n",
    "    # Iterate through lines\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        # Ignore empty lines\n",
    "        if stripped_line == \"\":\n",
    "            continue\n",
    "        \n",
    "        # If the line starts with '#', it is a comment line\n",
    "        if stripped_line[0] == '#':\n",
    "            comment_lines += 1\n",
    "        else:\n",
    "            # Otherwise, it is a line of code\n",
    "            code_lines += 1\n",
    "\n",
    "    # Check if there are no lines of code to prevent division by zero\n",
    "    if code_lines == 0:\n",
    "        return \"No lines of code present\"\n",
    "    \n",
    "    # Calculate and return the ratio\n",
    "    return comment_lines / code_lines\n",
    "\n",
    "def comment_ratio(df):\n",
    "    #Initialize counter\n",
    "    ratio = 0\n",
    "    for i in range(len(df)):\n",
    "        ratio+=calculate_comment_ratio(df.iloc[i]['gen_code'])\n",
    "    return ratio/len(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = comment_ratio(lbl_c_mtbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Assign the list of numbers \"{A}\" to a variable named \"my_numbers\".', 'Count the number of negative numbers in the list as \"n_neg\".', 'Count the number of positive numbers in the list as \"n_pos\".', 'Print out the larger number of those two.']\n"
     ]
    }
   ],
   "source": [
    "print(lbl_c_mtbp.iloc[4]['prompts'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
