{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MTPB Data: step-by-step instructions --> incremental code generation </h1>\n",
    "\n",
    "<p>\n",
    "generate code using MTPB's \"prompt\" instructions, alternating between prompts and code as shown below:\n",
    "\n",
    "Input: prompt1\n",
    "Output: code1\n",
    "\n",
    "Input: code1 + prompt2\n",
    "Output: code2\n",
    "\n",
    "Input: code1 + code2 + prompt3\n",
    "Output: code3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "\n",
    "from santaC import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from get_data import read_json_line_format\n",
    "\n",
    "max_token_to_generate = 248\n",
    "model = MySantaCoder('GrdS', max_token_to_generate)\n",
    "\n",
    "# Load the data\n",
    "mtbp_path = 'data/mtpb.jsonl'\n",
    "converted_mtbp_data = 'data/converted_mtpb.jsonl'\n",
    "mtbp_data = read_json_line_format(mtbp_path)\n",
    "converted_mtbp_data = read_json_line_format(converted_mtbp_data)\n",
    "mtbp_data['signature'] = converted_mtbp_data['signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 'def count_zeros(ars):\\n\\t# Initialize counter to zero\\n\\tcounter = 0\\n\\t# Loop over each element in the list\\n\\tfor i in ars:\\n\\t\\t# Increment counter if the element is zero\\n\\t\\tif i == 0:\\n\\t\\t\\tcounter += 1\\n\\t# Return the count of zeros\\n\\treturn counter'\n",
    "test2 = 'def first_element(ars):\\n\\t# Assign the first element of the list to a variable\\n\\tfirst = ars[0]\\n\\t# Return the first element\\n\\treturn first'\n",
    "test3 = 'def sum_while(ars):\\n\\t# Initialize variables\\n\\ttotal = 0\\n\\ti = 0\\n\\t# While loop until reaching the end of the list\\n\\twhile i < len(ars):\\n\\t\\t# Add current value to total\\n\\t\\ttotal += ars[i]\\n\\t\\t# Increment the index\\n\\t\\ti += 1\\n\\t# Return the total sum\\n\\treturn total'\n",
    "test4 = 'def filter_negatives(ars):\\n\\t# Initialize an empty list for positive numbers\\n\\tpositives = []\\n\\t# Loop over each element in the list\\n\\tfor num in ars:\\n\\t\\t# Add number to the list if it\\'s non-negative\\n\\t\\tif num >= 0:\\n\\t\\t\\tpositives.append(num)\\n\\t# Return the list of non-negative numbers\\n\\treturn positives'\n",
    "test5 = 'def flatten_list(ars):\\n\\t# Initialize an empty list for the result\\n\\tflattened = []\\n\\t# Loop over each element in the list\\n\\tfor sublist in ars:\\n\\t\\t# Loop over each element in the sublist\\n\\t\\tfor item in sublist:\\n\\t\\t\\t# Add item to the flattened list\\n\\t\\t\\tflattened.append(item)\\n\\t# Return the flattened list\\n\\treturn flattened'\n",
    "lines1 = test1.split('\\n')\n",
    "lines2 = test2.split('\\n')\n",
    "lines3 = test3.split('\\n')\n",
    "lines4 = test4.split('\\n')\n",
    "lines5 = test5.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from santaC import *\n",
    "from generation_processing import *\n",
    "\n",
    "def generating_step_by_step(model, data, stop_words, keep_context = True, early_stopping = None):\n",
    "    \"\"\"Generating code step by step \n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    for j in range(len(data)):\n",
    "        if early_stopping is not None and j > early_stopping:\n",
    "            break\n",
    "        # start with the signature for the incoming problem\n",
    "        code = data.iloc[j]['signature']\n",
    "        # initiate the list of prompt to generate\n",
    "        prompts = data.iloc[j]['prompts']\n",
    "        # Iterate over each prompt\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            # Add the prompt to the previously generated code\n",
    "            input_text = code + '\\n\\t' + '#' + prompt\n",
    "\n",
    "            # Encode the input text\n",
    "            input_ids = model.tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "            # Generate the output\n",
    "            output_ids = model.forward(input_ids)\n",
    "\n",
    "            # Decode the output\n",
    "            output_text = model.decode_output(output_ids[0])\n",
    "\n",
    "            code = generation_cut_off(output_text, stop_words, keep_context, i)\n",
    "            \n",
    "            # keep only the last code generated after the output\n",
    "            if keep_context==False:\n",
    "                # remove context if set to False\n",
    "                code = remove_context(code)\n",
    "\n",
    "        # print(\"Final generated code:\\n\", code)\n",
    "        codes.append(code)\n",
    "\n",
    "    return codes\n",
    "    \n",
    "\n",
    "stop_words = ['def', 'if', 'for', 'while']\n",
    "codes = generating_step_by_step(model=model, data=mtbp_data, stop_words=stop_words, keep_context = True)\n",
    "mtbp_data['gen_code'] = codes\n",
    "mtbp_data.to_csv('data/step_by_step/structural1_mtbp_with_context_Sampling.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the generation cut off function to see if it works properly:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploration of the outputs<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from generation_processing import *\n",
    "path_to_data = 'data/MTBP/baseline/MTBP_Greedy_solutions.csv'\n",
    "sampling_data = pd.read_csv(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cut_off_function_baselines(sampling_data)\n",
    "formatted_data = format_for_testing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data.to_csv('data/MTBP/baseline/MTBP_Processed_Greedy_solutions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "test = ast.literal_eval(sampling_data.iloc[0]['test_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.read_csv('data/MTBP/reports/reports_structural_mtbp_with_context_Sampling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.0, 0.0, 0.0, 0.0, 0.0]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports.iloc[13]['Pass_one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comment_ratio(func_code):\n",
    "    # Split the code into lines\n",
    "    lines = func_code.strip().split('\\n')\n",
    "    # Initialize counters\n",
    "    code_lines = 0\n",
    "    comment_lines = 0\n",
    "    # Iterate through lines\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        # Ignore empty lines\n",
    "        if stripped_line == \"\":\n",
    "            continue\n",
    "        \n",
    "        # If the line starts with '#', it is a comment line\n",
    "        if stripped_line[0] == '#':\n",
    "            comment_lines += 1\n",
    "        else:\n",
    "            # Otherwise, it is a line of code\n",
    "            code_lines += 1\n",
    "\n",
    "    # Check if there are no lines of code to prevent division by zero\n",
    "    if code_lines == 0:\n",
    "        return \"No lines of code present\"\n",
    "    \n",
    "    # Calculate and return the ratio\n",
    "    return comment_lines / code_lines\n",
    "\n",
    "def comment_ratio(df):\n",
    "    #Initialize counter\n",
    "    ratio = 0\n",
    "    for i in range(len(df)):\n",
    "        ratio+=calculate_comment_ratio(df.iloc[i]['gen_code'])\n",
    "    return ratio/len(df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
