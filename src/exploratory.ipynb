{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MTPB Data: step-by-step instructions --> incremental code generation </h1>\n",
    "\n",
    "<p>\n",
    "generate code using MTPB's \"prompt\" instructions, alternating between prompts and code as shown below:\n",
    "\n",
    "Input: prompt1\n",
    "Output: code1\n",
    "\n",
    "Input: code1 + prompt2\n",
    "Output: code2\n",
    "\n",
    "Input: code1 + code2 + prompt3\n",
    "Output: code3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def read_json_line_format(path_to_file):\n",
    "    \"\"\"\n",
    "        Read a JSON Lines format and store it into a dataframe.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path_to_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "    return df\n",
    "########################### Unused yet ###############################\n",
    "def extract_bracket_content(text):\n",
    "    pattern = \"{(.*?)}\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match is not None:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def managing_prompts_with_input(prompts, input):\n",
    "    \"\"\"\n",
    "        This function gives an example of the architecture of the input\n",
    "    \"\"\"\n",
    "    # we will simply add an example of the architecture of the first input. eg {input} for example : 'input' = [1,2,3]\n",
    "    processed_prompts = []\n",
    "    # Look for the prompt to change\n",
    "    for prompt in prompts:\n",
    "        # extract the input key to replace with the for example\n",
    "        input_key = extract_bracket_content(prompt)\n",
    "        if input_key is None:\n",
    "            processed_prompts.append(prompt)\n",
    "        else:\n",
    "            added_prompt = '{' + input_key + '}' + f' for example : {input_key} = {input[input_key]} '\n",
    "            processed_prompt = prompt.replace(input_key,added_prompt)\n",
    "\n",
    "    return processed_prompt\n",
    "#######################################################################\n",
    "\n",
    "def get_keys(input_list):\n",
    "    \"\"\"Get the list of unique input keys and list it (comma separated).\n",
    "    \"\"\"\n",
    "    keys = set()\n",
    "    for d in input_list:\n",
    "        keys.update(d.keys())\n",
    "    keys = sorted(list(keys))  # sort keys for consistent output\n",
    "    return ','.join(keys)\n",
    "\n",
    "def processing_name(name):\n",
    "    \"\"\"Processing the name of the problem to match the syntax of a function\n",
    "    \"\"\"\n",
    "    name = name.lower()  # convert to lowercase\n",
    "    name = re.sub('[^a-z0-9 ]', '', name)  # remove any non-alphanumeric characters (except spaces)\n",
    "    name = re.sub(' ', '_', name)  # replace spaces with underscores\n",
    "    return name\n",
    "\n",
    "def create_signature_for_function(data):\n",
    "    \"\"\"Create the function signature for each problem.\n",
    "    \"\"\"\n",
    "    # initiate a list of signature\n",
    "    signatures = []\n",
    "    # loop over all the rows\n",
    "    for i in range(len(data)):\n",
    "        # extract the name of the according problem\n",
    "        name = data.iloc[i]['name']\n",
    "        # process the name\n",
    "        name = processing_name(name)\n",
    "        # get the input\n",
    "        inputs = data.iloc[i]['inputs']\n",
    "        # extract the name\n",
    "        input_keys = get_keys(inputs)\n",
    "        # create the function signature architecture\n",
    "        signature = f'def {name}({input_keys}):'\n",
    "        # adding the signature to the list\n",
    "        signatures.append(signature)\n",
    "    \n",
    "    data['signature'] = signatures\n",
    "    return data\n",
    "\n",
    "# Call the functions\n",
    "mtbp_path = 'data/mtpb.jsonl'\n",
    "mtbp_data = read_json_line_format(mtbp_path)\n",
    "mtbp_data = create_signature_for_function(mtbp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "from santaC import *\n",
    "\n",
    "max_token_to_generate = 128\n",
    "model = MySantaCoder('SmplM', max_token_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from santaC import *\n",
    "\n",
    "\n",
    "def get_code_for_prompt(code_text, prompt_index, keep_context=True):\n",
    "    lines = code_text.split('\\n')\n",
    "    prompt_count = 0\n",
    "    start_index = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('#'):  # we have a new prompt\n",
    "            if prompt_count == prompt_index:  # we have reached the desired prompt\n",
    "                break\n",
    "            prompt_count += 1\n",
    "            if not keep_context:\n",
    "                start_index = i\n",
    "    return '\\n'.join(lines[start_index:i+2])  # include the next line after the prompt\n",
    "\n",
    "def get_code_for_prompt_old(code_text, prompt_index):\n",
    "    lines = code_text.split('\\n')\n",
    "    prompt_count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('#'):  # we have a new prompt\n",
    "            if prompt_count == prompt_index:  # we have reached the desired prompt\n",
    "                break\n",
    "            prompt_count += 1\n",
    "    return '\\n'.join(lines[:i+2])  # include the next line after the prompt\n",
    "\n",
    "def remove_context(code):\n",
    "    \"\"\"remove all lines starting with '\\t#' \n",
    "    \"\"\"\n",
    "    lines = code.split('\\n')\n",
    "    # keep only lines that don't start with '\\t#'\n",
    "    lines = [line for line in lines if not line.startswith('\\t#')]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def generating_step_by_step_with_context(model, data, keep_context = True):\n",
    "    \"\"\"Generating code step by step \n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    for j in range(len(data)):\n",
    "        # start with the signature for the incoming problem\n",
    "        code = data.iloc[j]['signature']\n",
    "        if j > 2 : \n",
    "            break\n",
    "        else:\n",
    "            # initiate the list of prompt to generate\n",
    "            prompts = data.iloc[j]['prompts']\n",
    "            # Iterate over each prompt\n",
    "            for i, prompt in enumerate(prompts):\n",
    "                # show what prompts is currently beeing used\n",
    "                print(f\"Prompt {i+1}: {prompt}\")\n",
    "                \n",
    "                # Add the prompt to the previously generated code\n",
    "                input_text = code + '\\n\\t' + '#' + prompt\n",
    "                \n",
    "                # Encode the input text\n",
    "                input_ids = model.tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "                # Generate the output\n",
    "                output_ids = model.forward(input_ids)\n",
    "\n",
    "                # Decode the output\n",
    "                output_text = model.decode_output(output_ids[0])\n",
    "                \n",
    "                # keep only the last code generated after the output\n",
    "                code = get_code_for_prompt_old(output_text, i) \n",
    "                \n",
    "        if keep_context==False:\n",
    "            # remove context if set to False\n",
    "            code = remove_context(code)\n",
    "\n",
    "        # print(\"Final generated code:\\n\", code)\n",
    "        codes.append(code)\n",
    "    \n",
    "\n",
    "\n",
    "generating_step_by_step_with_context(model, mtbp_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def function(a):\n",
      "\tmy_string=a\n",
      "\tprint(my_string)\n",
      "\tprint(my_string, my_string)\n",
      "\t#return the string\n",
      "\treturn my_string\n"
     ]
    }
   ],
   "source": [
    "trys = 'def function(a):\\n\\t#Assign the value a to \"my_string\"\\n\\tmy_string=a\\n\\t#print the value ones\\n\\tprint(my_string)\\n\\t#print the value twice\\n\\tprint(my_string, my_string)\\n\\t#return the string\\n\\treturn my_string'\n",
    "trys_wocon = 'def function(a):\\n\\tmy_string=a\\n\\tprint(my_string)\\n\\tprint(my_string, my_string)\\n\\t#return the string\\n\\treturn my_string'\n",
    "print(trys_wocon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_for_prompt(code_text, prompt_index, keep_context=True):\n",
    "    lines = code_text.split('\\n')\n",
    "    prompt_count = 0\n",
    "    start_index = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('#'):  # we have a new prompt\n",
    "            if prompt_count == prompt_index:  # we have reached the desired prompt\n",
    "                break\n",
    "            prompt_count += 1\n",
    "            if not keep_context:\n",
    "                start_index = i\n",
    "    return '\\n'.join(lines[start_index:i+2])  # include the next line after the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_for_prompt_old(code_text, prompt_index):\n",
    "    lines = code_text.split('\\n')\n",
    "    prompt_count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('#'):  # we have a new prompt\n",
    "            if prompt_count == prompt_index:  # we have reached the desired prompt\n",
    "                break\n",
    "            prompt_count += 1\n",
    "    return '\\n'.join(lines[:i+2])  # include the next line after the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def function(a):\n",
      "\tmy_string=a\n",
      "\tprint(my_string)\n",
      "\tprint(my_string, my_string)\n",
      "\t#return the string\n",
      "\treturn my_string\n"
     ]
    }
   ],
   "source": [
    "output = get_code_for_prompt_old(trys_wocon, 0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2]])\n"
     ]
    }
   ],
   "source": [
    "input_ids = model.tokenizer.encode('#', return_tensors='pt')\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompts           [Assign the string \"{A}\" to a variable named \"...\n",
       "inputs            [{'A': 'abcde'}, {'A': 'abcdecadeCADE'}, {'A':...\n",
       "outputs           [[a, b, c, d, e], [a, b, c, d, e], [a], [ , e,...\n",
       "max_gen_length                                                128.0\n",
       "category                                                     string\n",
       "name                                                Sandwich string\n",
       "description        Append a string in the middle of another string.\n",
       "id                                                                1\n",
       "signature                                   def sandwich_string(A):\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtbp_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "indice = 1\n",
    "code_to_prompt = mtbp_data.iloc[indice]['signature'] + \"\\n\\t\" + '#' + mtbp_data.iloc[indice]['prompts'][0]\n",
    "input_ids = model.tokenizer.encode(code_to_prompt, return_tensors='pt')\n",
    "\n",
    "# Generate the output\n",
    "output_ids = model.forward(input_ids)\n",
    "\n",
    "# Decode the output\n",
    "output_text = model.decode_output(output_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def normalize_integer_list(numbers):\n",
      "\t#Define a list of integers named \"numbers\" with the values {numbers}.\n",
      "\treturn [int(i) for i in numbers]\n",
      "\n",
      "def is_int(number):\n",
      "\t#Check whether the input \"number\" is an integer.\n",
      "\treturn isinstance(number, int)\n",
      "\n",
      "def is_float(number):\n",
      "\t#Check whether the input \"number\" is a float.\n",
      "\treturn isinstance(number, float)\n",
      "\n",
      "def is_string(string):\n",
      "\t#Check whether the input \"string\" is a string.\n",
      "\treturn isinstance(string, str)\n",
      "\n",
      "def is_tuple(t):\n",
      "\t#Check whether the input \"t\"\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def sandwich_string(A):\\n\\t#Assign the string \"{A}\" to a variable named \"my_string\".\\n\\tmy_string = \"{A}\"\\n\\t#Print the string \"sandwich\" to the screen.\\n\\tprint(my_string)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_code_for_prompt(output_text, 1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
