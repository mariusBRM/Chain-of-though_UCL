{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MTPB Data: step-by-step instructions --> incremental code generation </h1>\n",
    "\n",
    "<p>\n",
    "generate code using MTPB's \"prompt\" instructions, alternating between prompts and code as shown below:\n",
    "\n",
    "Input: prompt1\n",
    "Output: code1\n",
    "\n",
    "Input: code1 + prompt2\n",
    "Output: code2\n",
    "\n",
    "Input: code1 + code2 + prompt3\n",
    "Output: code3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def read_json_line_format(path_to_file):\n",
    "    \"\"\"\n",
    "        Read a JSON Lines format and store it into a dataframe.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path_to_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "    return df\n",
    "########################### Unused yet ###############################\n",
    "def extract_bracket_content(text):\n",
    "    pattern = \"{(.*?)}\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match is not None:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def managing_prompts_with_input(prompts, input):\n",
    "    \"\"\"\n",
    "        This function gives an example of the architecture of the input\n",
    "    \"\"\"\n",
    "    # we will simply add an example of the architecture of the first input. eg {input} for example : 'input' = [1,2,3]\n",
    "    processed_prompts = []\n",
    "    # Look for the prompt to change\n",
    "    for prompt in prompts:\n",
    "        # extract the input key to replace with the for example\n",
    "        input_key = extract_bracket_content(prompt)\n",
    "        if input_key is None:\n",
    "            processed_prompts.append(prompt)\n",
    "        else:\n",
    "            added_prompt = '{' + input_key + '}' + f' for example : {input_key} = {input[input_key]} '\n",
    "            processed_prompt = prompt.replace(input_key,added_prompt)\n",
    "\n",
    "    return processed_prompt\n",
    "#######################################################################\n",
    "\n",
    "def get_keys(input_list):\n",
    "    \"\"\"Get the list of unique input keys and list it (comma separated).\n",
    "    \"\"\"\n",
    "    keys = set()\n",
    "    for d in input_list:\n",
    "        keys.update(d.keys())\n",
    "    keys = sorted(list(keys))  # sort keys for consistent output\n",
    "    return ','.join(keys)\n",
    "\n",
    "def processing_name(name):\n",
    "    \"\"\"Processing the name of the problem to match the syntax of a function\n",
    "    \"\"\"\n",
    "    name = name.lower()  # convert to lowercase\n",
    "    name = re.sub('[^a-z0-9 ]', '', name)  # remove any non-alphanumeric characters (except spaces)\n",
    "    name = re.sub(' ', '_', name)  # replace spaces with underscores\n",
    "    return name\n",
    "\n",
    "def create_signature_for_function(data):\n",
    "    \"\"\"Create the function signature for each problem.\n",
    "    \"\"\"\n",
    "    # initiate a list of signature\n",
    "    signatures = []\n",
    "    # loop over all the rows\n",
    "    for i in range(len(data)):\n",
    "        # extract the name of the according problem\n",
    "        name = data.iloc[i]['name']\n",
    "        # process the name\n",
    "        name = processing_name(name)\n",
    "        # get the input\n",
    "        inputs = data.iloc[i]['inputs']\n",
    "        # extract the name\n",
    "        input_keys = get_keys(inputs)\n",
    "        # create the function signature architecture\n",
    "        signature = f'def {name}({input_keys}):'\n",
    "        # adding the signature to the list\n",
    "        signatures.append(signature)\n",
    "    \n",
    "    data['signature'] = signatures\n",
    "    return data\n",
    "\n",
    "# Call the functions\n",
    "mtbp_path = 'data/mtpb.jsonl'\n",
    "mtbp_data = read_json_line_format(mtbp_path)\n",
    "mtbp_data = create_signature_for_function(mtbp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "from santaC import *\n",
    "\n",
    "max_token_to_generate = 128\n",
    "model = MySantaCoder('GrdS', max_token_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: Assign the string \"{A}\" to a variable named \"my_string\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2: Lowercase the given string \"my_string\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3: Assign the distinct characters of the string to a variable named \"chars\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4: Sort these characters in alphabetical order.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5: Print the resulting list of characters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final generated code:\n",
      " def sandwich_string(A):\n",
      "\tmy_string = \"{A}\"\n",
      "\tmy_string = my_string.lower()\n",
      "\tmy_list = my_string.split()\n",
      "\tchars = set(my_list)\n",
      "\tsandwich = \"\".join(chars)\n",
      "\treturn sandwich\n",
      "\n",
      "#Create a function named \"sandwich_string\" that takes a string as an argument and returns the same string, but with all the characters in the string in lower case.\n",
      "\n",
      "Prompt 1: Define a list of integers named \"numbers\" with the values {numbers}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2: Calculate the sum of the elements in variable \"numbers\" and store the result to variable \"total\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3: Divide each element of the list by the total and multiply by 100, store the result to variable \"normalized\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4: Convert each element in variable \"normalized\" into a formatted string with single decimal point and store the result into \"formatted\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5: Print the variable \"formatted\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final generated code:\n",
      " def normalize_integer_list(numbers):\n",
      "\ttotal = sum(numbers)\n",
      "\tnormalized_numbers = []\n",
      "\tfor number in numbers:\n",
      "\t\tnormalized_numbers.append(number/total*100)\n",
      "\treturn normalized_numbers\n",
      "\n",
      "def normalize_float_list(numbers):\n",
      "\ttotal = sum(numbers)\n",
      "\tnormalized_numbers = []\n",
      "\tfor number in numbers:\n",
      "\t\tnormalized_numbers.append(number/total*100)\n",
      "\treturn normalized_numbers\n",
      "\n",
      "def normalize_string_list(numbers):\n",
      "\ttotal = sum\n",
      "\tformatted = []\n",
      "\tfor number in numbers:\n",
      "\t\tformatted.append(str(number/total*100))\n",
      "\treturn formatted\n",
      "\n",
      "def normalize_list(numbers):\n",
      "\tif type(numbers) == list:\n",
      "\t\tif type(numbers[0]) == int:\n",
      "\t\t\treturn normalize_integer_list(numbers)\n",
      "\t\telif type(numbers[0]) == float:\n",
      "\t\t\treturn normalize_float_list(numbers)\n",
      "\t\telif type(numbers[0]) == str:\n",
      "\t\t\treturn normalize_string_list(numbers)\n",
      "\telse:\n",
      "\t\treturn numbers\n",
      "\n",
      "def normalize_list_of_lists(lists):\n",
      "\tif type(lists) == list:\n",
      "\t\tif type(lists[0]) == list:\n",
      "\t\t\treturn normalize_list(lists)\n",
      "\t\telse:\n",
      "\t\t\treturn lists\n",
      "\telse:\n",
      "\t\treturn lists\n",
      "\n",
      "def normalize_list_of_lists_of_lists(lists):\n",
      "\tif type(lists) == list:\n",
      "\t\tif type(lists[0]) == list:\n",
      "\t\t\tif type(lists[0][0]) == list:\n",
      "\t\t\t\treturn normalize_list\n",
      "Prompt 1: Write a function that takes an integer minutes and converts it to seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2: Write a function that takes an integer hours and converts it to seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3: Print the total seconds of {a1} hours and {a2} minutes.\n",
      "Final generated code:\n",
      " def convert_time(a1,a2):\n",
      "\treturn a1*3600+a2*60\n",
      "\n",
      "def convert_time_to_seconds(a1,a2):\n",
      "\treturn a1*3600+a2*60\n",
      "\n",
      "def convert_time_to_minutes(a1,a2):\n",
      "\treturn a1*60+a2\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from santaC import *\n",
    "\n",
    "\n",
    "def get_code_for_prompt(code_text, prompt_index):\n",
    "    lines = code_text.split('\\n')\n",
    "    prompt_count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('#'):  # we have a new prompt\n",
    "            if prompt_count == prompt_index:  # we have reached the desired prompt\n",
    "                break\n",
    "            prompt_count += 1\n",
    "    return '\\n'.join(lines[:i+2])  # include the next line after the prompt\n",
    "\n",
    "def remove_context(code):\n",
    "    #TODO: remove all lines starting with '\\t#'\n",
    "    lines = code.split('\\n')\n",
    "    # keep only lines that don't start with '\\t#'\n",
    "    lines = [line for line in lines if not line.startswith('\\t#')]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def generating_step_by_step_with_context(model, data, keep_context = True):\n",
    "    \"\"\"Generating code step by step \n",
    "    \"\"\"\n",
    "    # Adding it to \n",
    "    for j in range(len(data)):\n",
    "        # start with the signature for the incoming problem\n",
    "        code = data.iloc[j]['signature']\n",
    "        if j > 2 : \n",
    "            break\n",
    "        else:\n",
    "            # initiate the list of prompt to generate\n",
    "            prompts = data.iloc[j]['prompts']\n",
    "            # Iterate over each prompt\n",
    "            for i, prompt in enumerate(prompts):\n",
    "                # show what prompts is currently beeing used\n",
    "                print(f\"Prompt {i+1}: {prompt}\")\n",
    "                \n",
    "                # Add the prompt to the previously generated code\n",
    "                input_text = code + '\\n\\t' + '#' + prompt\n",
    "                \n",
    "                # Encode the input text\n",
    "                input_ids = model.tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "                # Generate the output\n",
    "                output_ids = model.forward(input_ids)\n",
    "\n",
    "                # Decode the output\n",
    "                output_text = model.decode_output(output_ids[0])\n",
    "\n",
    "                # Process output\n",
    "                code = get_code_for_prompt(output_text, i)\n",
    "\n",
    "                # remove context if set to False\n",
    "                if keep_context == False:\n",
    "                    code = remove_context(code)\n",
    "\n",
    "        print(\"Final generated code:\\n\", code)\n",
    "\n",
    "\n",
    "generating_step_by_step_with_context(model, mtbp_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def function(a):\n",
      "\t#Assign the value a to \"my_string\"\n",
      "\tmy_string=a\n",
      "\t#print the value ones\n",
      "\tprint(my_string)\n",
      "\t#print the value twice\n",
      "\tprint(my_string, my_string)\n",
      "\t#return the string\n",
      "\treturn my_string\n"
     ]
    }
   ],
   "source": [
    "trys = 'def function(a):\\n\\t#Assign the value a to \"my_string\"\\n\\tmy_string=a\\n\\t#print the value ones\\n\\tprint(my_string)\\n\\t#print the value twice\\n\\tprint(my_string, my_string)\\n\\t#return the string\\n\\treturn my_string'\n",
    "\n",
    "print(trys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_for_prompt(code_text, prompt_index):\n",
    "    lines = code_text.split('\\n')\n",
    "    prompt_count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('#'):  # we have a new prompt\n",
    "            if prompt_count == prompt_index:  # we have reached the desired prompt\n",
    "                break\n",
    "            prompt_count += 1\n",
    "    return '\\n'.join(lines[:i+2])  # include the next line after the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def function(a):\n",
      "\t#Assign the value a to \"my_string\"\n",
      "\tmy_string=a\n",
      "\t#print the value ones\n",
      "\tprint(my_string)\n",
      "\t#print the value twice\n",
      "\tprint(my_string, my_string)\n",
      "\t#return the string\n",
      "\treturn my_string\n"
     ]
    }
   ],
   "source": [
    "output = get_code_for_prompt(trys, 3)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "indice = 0\n",
    "code_to_prompt = mtbp_data.iloc[indice]['signature'] + \"\\n\\t\" + \"#\" + mtbp_data.iloc[indice]['prompts'][0]\n",
    "input_ids = model.tokenizer.encode(code_to_prompt, return_tensors='pt')\n",
    "\n",
    "# Generate the output\n",
    "output_ids = model.forward(input_ids)\n",
    "\n",
    "# Decode the output\n",
    "output_text = model.decode_output(output_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sandwich_string(A):\n",
      "\t#Assign the string \"{A}\" to a variable named \"my_string\".\n",
      "\tmy_string = \"{A}\"\n",
      "\t#Print the string \"sandwich\" to the screen.\n",
      "\tprint(my_string)\n",
      "\t#Return the string \"sandwich\" to the function.\n",
      "\treturn my_string\n",
      "\n",
      "#Call the function sandwich_string with the value of 10.\n",
      "sandwich_string(10)\n",
      "\n",
      "#Assign the string \"sandwich\" to a variable named \"my_string\".\n",
      "my_string = \"sandwich\"\n",
      "#Print the string \"sandwich\" to the screen.\n",
      "print(my_string)\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def sandwich_string(A):\\n\\t#Assign the string \"{A}\" to a variable named \"my_string\".\\n\\tmy_string = \"{A}\"\\n\\t#Print the string \"sandwich\" to the screen.\\n\\tprint(my_string)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_code_for_prompt(output_text, 1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
