{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MTPB Data: step-by-step instructions --> incremental code generation </h1>\n",
    "\n",
    "<p>\n",
    "generate code using MTPB's \"prompt\" instructions, alternating between prompts and code as shown below:\n",
    "\n",
    "Input: prompt1\n",
    "Output: code1\n",
    "\n",
    "Input: code1 + prompt2\n",
    "Output: code2\n",
    "\n",
    "Input: code1 + code2 + prompt3\n",
    "Output: code3</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploration of the reports and outputs<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report\n",
      "number of Pass One for the baseLine: 88.0 out of 575\n",
      "number of Pass One for the line by line with context: 10.0 out of 575\n",
      "number of Pass One for the line by line without context: 33.0 out of 575\n",
      "number of Pass One for the structural Sampling generation: 52.0 out of 575\n",
      "number of Pass One for the structural Greddy generation: 62.0 out of 575\n",
      "number of Pass One for the structural Greddy generation no#: 73.0 out of 575\n",
      "number of Pass One for the context no cut off: 10.0 out of 575\n",
      "number of Pass One for lenght penalty on tokens: 14.0 out of 575\n",
      "number of Pass One for lenght penalty on words: 10.0 out of 575\n",
      "number of Pass One for length penalty on lines: 11.0 out of 575\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def count_pass_one_completed(df):\n",
    "    count_succes = 0\n",
    "    indexes_successful = []\n",
    "    number_of_success = []\n",
    "    for i in range(len(df)):\n",
    "        test = ast.literal_eval(df.iloc[i]['Pass_one'])\n",
    "        count_succes+=sum(test)\n",
    "        if sum(test) >= 1:\n",
    "            indexes_successful.append(i)\n",
    "            number_of_success.append(sum(test))\n",
    "    \n",
    "    return count_succes, number_of_success, indexes_successful\n",
    "\n",
    "# instanciation\n",
    "report_baseline = pd.read_csv('data/MTBP/reports/reports_MTBP_Processed_Greedy_solutions.csv')\n",
    "report_lbl_w = pd.read_csv('data/MTBP/reports/reports_line_by_line_with_context_Sampling.csv')\n",
    "report_lbl_wo = pd.read_csv('data/MTBP/reports/reports_line_by_line_without_context_Sampling.csv')\n",
    "report_str_S = pd.read_csv('data/MTBP/reports/reports_structural_mtbp_with_context_Sampling.csv') \n",
    "report_str_G = pd.read_csv('data/MTBP/reports/reports_structural_mtbp_with_context_Greedy.csv') \n",
    "report_str_noC_G = pd.read_csv('data/MTBP/reports/reports_no#_structural_mtbp_with_context_Greedy.csv')\n",
    "report_prompy_vs_context = pd.read_csv('data/MTBP/reports/reports_prompt_vs_context.csv')\n",
    "report_token_pen = pd.read_csv('data/MTBP/reports/reports_token_length_penalty.csv')\n",
    "report_word_pen = pd.read_csv('data/MTBP/reports/reports_words_length_penalty.csv')\n",
    "report_line_pen = pd.read_csv('data/MTBP/reports/reports_lines_lenght_penalty.csv')\n",
    "\n",
    "\n",
    "_,success_base, list_baseline = count_pass_one_completed(report_baseline)\n",
    "_,success_lbl_w,list_lbl_w = count_pass_one_completed(report_lbl_w)\n",
    "_,success_lbl_wo,list_lbl_wo = count_pass_one_completed(report_lbl_wo)\n",
    "_,success_str_S,list_stru_S = count_pass_one_completed(report_str_S)\n",
    "_,success_str_G,list_stru_G = count_pass_one_completed(report_str_G)\n",
    "_,success_str_noC_G,list_stru_noC_G = count_pass_one_completed(report_str_noC_G)\n",
    "\n",
    "_,success_prompt_context,list_prompt_context = count_pass_one_completed(report_prompy_vs_context)\n",
    "_,success_token_pen,list_token_pen = count_pass_one_completed(report_token_pen)\n",
    "_,success_word_pen,list_word_pen = count_pass_one_completed(report_word_pen)\n",
    "_,success_line_pen,list_line_pen = count_pass_one_completed(report_line_pen)\n",
    "\n",
    "print('report')\n",
    "print(f'number of Pass One for the baseLine: {count_pass_one_completed(report_baseline)[0]} out of 575')\n",
    "print(f'number of Pass One for the line by line with context: {count_pass_one_completed(report_lbl_w)[0]} out of 575')\n",
    "print(f'number of Pass One for the line by line without context: {count_pass_one_completed(report_lbl_wo)[0]} out of 575')\n",
    "print(f'number of Pass One for the structural Sampling generation: {count_pass_one_completed(report_str_S)[0]} out of 575')\n",
    "print(f'number of Pass One for the structural Greddy generation: {count_pass_one_completed(report_str_G)[0]} out of 575')\n",
    "print(f'number of Pass One for the structural Greddy generation no#: {count_pass_one_completed(report_str_noC_G)[0]} out of 575')\n",
    "\n",
    "print(f'number of Pass One for the context no cut off: {count_pass_one_completed(report_prompy_vs_context)[0]} out of 575')\n",
    "print(f'number of Pass One for lenght penalty on tokens: {count_pass_one_completed(report_token_pen)[0]} out of 575')\n",
    "print(f'number of Pass One for lenght penalty on words: {count_pass_one_completed(report_word_pen)[0]} out of 575')\n",
    "print(f'number of Pass One for length penalty on lines: {count_pass_one_completed(report_line_pen)[0]} out of 575')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Inspection of the output :</h2>\n",
    "Inspection of the following elements : [3, 4, 21, 29, 33, 35, 36, 58, 59, 79, 85, 90, 91, 97, 98, 100, 103, 107] or What worked with the baseline that doesn't work with the structural greedy step by step generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base = pd.read_csv('data/MTBP/baseline/MTBP_Processed_Greedy_solutions.csv')\n",
    "step_by_step = pd.read_csv('data/MTBP/step_by_step/structural_mtbp_with_context_Greedy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_sbs_to_b = []\n",
    "for i in list_stru_G:\n",
    "    if i not in list_baseline:\n",
    "        diff_sbs_to_b.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Inspection of the output : </h1>\n",
    "Inspection of the following elements : [31, 40, 48, 92, 94, 106, 113] or What worked with the step by step that didn't work with the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 113\n",
    "print('step by step :')\n",
    "print(step_by_step.iloc[index]['code_test'])\n",
    "print('===============')\n",
    "print('base :')\n",
    "print(base.iloc[index]['code_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 29, 33, 56, 72, 91, 93, 107]\n",
      "[25, 26, 28, 31, 40, 48, 51, 53, 54, 55, 56, 67, 72, 89, 92, 93, 94, 106, 108, 113]\n"
     ]
    }
   ],
   "source": [
    "baseline = list_baseline\n",
    "step_by_step = list_stru_G\n",
    "\n",
    "print(baseline)\n",
    "print(step_by_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comment_ratio(func_code):\n",
    "    # Split the code into lines\n",
    "    lines = func_code.strip().split('\\n')\n",
    "    # Initialize counters\n",
    "    code_lines = 0\n",
    "    comment_lines = 0\n",
    "    # Iterate through lines\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        # Ignore empty lines\n",
    "        if stripped_line == \"\":\n",
    "            continue\n",
    "        \n",
    "        # If the line starts with '#', it is a comment line\n",
    "        if stripped_line[0] == '#':\n",
    "            comment_lines += 1\n",
    "        else:\n",
    "            # Otherwise, it is a line of code\n",
    "            code_lines += 1\n",
    "\n",
    "    # Check if there are no lines of code to prevent division by zero\n",
    "    if code_lines == 0:\n",
    "        return \"No lines of code present\"\n",
    "    \n",
    "    # Calculate and return the ratio\n",
    "    return comment_lines / code_lines\n",
    "\n",
    "def comment_ratio(df):\n",
    "    #Initialize counter\n",
    "    ratio = 0\n",
    "    for i in range(len(df)):\n",
    "        ratio+=calculate_comment_ratio(df.iloc[i]['gen_code'])\n",
    "    return ratio/len(df)\n",
    "\n",
    "def best_candidate(df):\n",
    "    # Compute the average rate of Pass_one for each candidate\n",
    "    df['average'] = df['Pass_one'].apply(lambda x: sum(x) / len(x) if len(x) != 0 else 0)\n",
    "\n",
    "    # Identify the candidate with the highest average rate\n",
    "    best_candidate = df.loc[df['average'].idxmax()]['candidate']\n",
    "\n",
    "    return best_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis of the output</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def check_syntax(code):\n",
    "    try:\n",
    "        compile(code, \"<string>\", \"exec\")\n",
    "        # print('Syntax is ok')\n",
    "        return True\n",
    "    except SyntaxError:\n",
    "        # print('Problem with Syntax', SyntaxError)\n",
    "        return False\n",
    "\n",
    "def add_check_syntax_of_generated_code(df):\n",
    "    list_check = []\n",
    "    for i in range(len(df)):\n",
    "        candidate = ast.literal_eval(df.iloc[i]['candidate'])\n",
    "        if check_syntax(candidate[0][0]):\n",
    "            list_check.append(1)\n",
    "        else:\n",
    "            list_check.append(0)\n",
    "\n",
    "    df['syntax_check'] = list_check\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_baseline = add_check_syntax_of_generated_code(report_baseline)\n",
    "report_lbl_w = add_check_syntax_of_generated_code(report_lbl_w)\n",
    "report_lbl_wo = add_check_syntax_of_generated_code(report_lbl_wo)\n",
    "report_str_S = add_check_syntax_of_generated_code(report_str_S)\n",
    "report_str_G = add_check_syntax_of_generated_code(report_str_G)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from santaC import *\n",
    "\n",
    "model = MySantaCoder('GrdS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
