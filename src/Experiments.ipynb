{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer(Dataset):\n",
    "    def __init__(self, data, path_to_hub):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(path_to_hub) # Load your tokenizer here with a pre-specified vocabulary\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.data = data # a dataframe\n",
    "        self.content_name = 'instruction'\n",
    "        self.target_name = 'code'\n",
    "        self.list_test = 'test_list'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        text = self.data.iloc[index][self.content_name]\n",
    "        code = self.data.iloc[index][self.target_name]\n",
    "        test_list = self.data.iloc[index][self.list_test]\n",
    "\n",
    "        inputs = self.tokenizer(text, padding=True)\n",
    "        label = self.tokenizer.encode(code, padding=True)\n",
    "        tests = self.tokenizer.encode(test_list, padding=True)\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'tests' : torch.tensor(tests, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class MySantaCoder(nn.Module):\n",
    "    def __init__(self, generation_method, num_sol = 1):\n",
    "        super(MySantaCoder, self).__init__()\n",
    "        self.checkpoint = \"bigcode/santacoder\"\n",
    "        # self.checkpoint = model_path_to_hub\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.checkpoint, trust_remote_code=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)\n",
    "        self.max_new_tokens = 128\n",
    "\n",
    "        if generation_method == 'greedySearch':\n",
    "\n",
    "            self.generation_config = GenerationConfig(\n",
    "                num_beams = num_sol,\n",
    "                num_return_sequences = num_sol,\n",
    "                max_length = self.max_new_tokens,\n",
    "                eos_token_id=self.model.generation_config.eos_token_id,\n",
    "                bos_token_id=self.model.generation_config.bos_token_id\n",
    "                )\n",
    "        elif generation_method == 'samplingMethod' : \n",
    "     \n",
    "            self.generation_config = GenerationConfig(   \n",
    "                do_sample = True,  \n",
    "                num_beams = num_sol,\n",
    "                num_return_sequences = num_sol,\n",
    "                top_p = 0.8,\n",
    "                temperature = 0.95,\n",
    "                max_length = self.max_new_tokens,\n",
    "                eos_token_id=self.model.generation_config.eos_token_id,\n",
    "                bos_token_id=self.model.generation_config.bos_token_id\n",
    "                )\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids = input_ids.unsqueeze(0)\n",
    "        outputs = self.model.generate(input_ids, self.generation_config)\n",
    "        return outputs\n",
    "\n",
    "    def decode_output(self, encoded_output):\n",
    "        output = self.tokenizer.decode(encoded_output)\n",
    "        return output\n",
    "\n",
    "    def post_generation_processing(self,code):\n",
    "        # split it into list of blocks\n",
    "        list_blocks = re.split('def |class |assert |print ', code)\n",
    "        if 'init' in list_blocks[1]:\n",
    "            fill_word = '\\nclass '\n",
    "        else:\n",
    "            fill_word = '\\ndef '\n",
    "        # keep only the first block\n",
    "        result = list_blocks[0] + fill_word + list_blocks[1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(test_loader, model, early_stoping = None):\n",
    "    \"\"\"\n",
    "    This function evaluate the model on the test data\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    final_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "          ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "          targets = data['labels'].to(device, dtype = torch.long)\n",
    "          tests = data['tests'].to(device, dtype = torch.long)\n",
    "          # forward\n",
    "          output = model.forward(ids).to(device)\n",
    "          # postprocessing output\n",
    "          decoded_output = [model.decode_output(t.cpu().numpy()) for t in output]\n",
    "          code_generated = [model.post_generation_processing(dec) for dec in decoded_output]\n",
    "\n",
    "          final_outputs.append(code_generated)\n",
    "\n",
    "    return final_outputs\n",
    "\n",
    "def save_generated_data(data, generated_code):\n",
    "  selected_feature = ['code', 'test_list']\n",
    "  data = data[selected_feature]\n",
    "  # add the new feature\n",
    "  data['generated_code'] = generated_code\n",
    "\n",
    "  data.to_csv(\"data/200_greedy_solutions.csv\", index=False)\n",
    "  return data\n",
    "\n",
    "def dataloading(data, path_to_hub, batch_size, num_workers, g, seed_worker):\n",
    "    # create dataset out of dataframe\n",
    "    dataset = MyTokenizer(data, path_to_hub)\n",
    "\n",
    "    # create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "        )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# instanciate the testing loader :\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "# setting the seed\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "\n",
    "# Create dataloader\n",
    "batch_size = 1\n",
    "num_workers = 0\n",
    "testing_data = pd.read_csv('data/mbpp_test.csv')\n",
    "PATH_TO_HUB = \"bigcode/santacoder\"\n",
    "\n",
    "\n",
    "testloader = dataloading(testing_data, PATH_TO_HUB, batch_size, num_workers, g, seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "model = MySantaCoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_function(input_string):\n",
    "    # Regular expression pattern to match Python function\n",
    "    pattern = re.compile(r\"(def .*?:.*?return .*?\\n)(?=\\n|\\Z)\", re.DOTALL)\n",
    "\n",
    "    # Find all matches of the pattern in the input string\n",
    "    matches = pattern.findall(input_string)\n",
    "\n",
    "    # If no complete function is found, return the original string\n",
    "    if not matches:\n",
    "        return input_string\n",
    "\n",
    "    # Return the first complete function\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_max_token(df):\n",
    "    max_token = 0\n",
    "    avg = 0\n",
    "    nm_to_be_generated = 0\n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        text = len(df.iloc[i]['text'])\n",
    "        code = len(df.iloc[i]['code'])\n",
    "        nm_to_be_generated += 10 + text\n",
    "        avg += code + text\n",
    "        nm_tokens = 1.1 * (text + code)\n",
    "        if  nm_tokens > max_token:\n",
    "            max_token = nm_tokens\n",
    "    \n",
    "    return max_token, avg/len(df), nm_to_be_generated/len(df)\n",
    "\n",
    "data = pd.read_csv('data/mbpp_test.csv')\n",
    "mx, avg, gen = find_max_token(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "greedy_two_data = pd.read_csv('../data/200_greedy_solutions.csv')\n",
    "\n",
    "# part of the processing\n",
    "import ast\n",
    "\n",
    "list_code = ast.literal_eval(greedy_two_data.iloc[0]['generated_code']) \n",
    "\n",
    "import re\n",
    "\n",
    "def extract_first_function(input_string):\n",
    "    # Regular expression pattern to match Python function\n",
    "    pattern = re.compile(r\"(def .*?:.*?return .*?\\n)(?=\\n|\\Z)\", re.DOTALL)\n",
    "\n",
    "    # Find all matches of the pattern in the input string\n",
    "    matches = pattern.findall(input_string)\n",
    "\n",
    "    # If no complete function is found, return the original string\n",
    "    if not matches:\n",
    "        return input_string\n",
    "\n",
    "    # Return the first complete function\n",
    "    result = matches[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# still need to remove '<|endoftext|>' --> Is it a problem cannot remove it idk why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def remove_Occ(s,ch):\n",
      "\t\"\"\"Write a python function to remove first and last occurrence of a given character from the string.\"\"\"\n",
      "\ti = 0\n",
      "\tj = len(s) - 1\n",
      "\twhile i < j:\n",
      "\t\tif s[i] == ch:\n",
      "\t\t\ti += 1\n",
      "\t\telif s[j] == ch:\n",
      "\t\t\tj -= 1\n",
      "\t\telse:\n",
      "\t\t\ti += 1\n",
      "\t\t\tj -= 1\n",
      "\treturn s[i+1:j+1]<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "def remove_Occ(s,ch):\n",
      "\t\"\"\"Write a python function to remove first and last occurrence of a given character from the string.\"\"\"\n",
      "\ti = 0\n",
      "\tj = len(s) - 1\n",
      "\twhile i < j:\n",
      "\t\tif s[i] == ch:\n",
      "\t\t\ti += 1\n",
      "\t\telif s[j] == ch:\n",
      "\t\t\tj -= 1\n",
      "\t\telse:\n",
      "\t\t\ti += 1\n",
      "\t\t\tj -= 1\n",
      "\treturn s[i+1:j+1]\n",
      "============\n",
      "def remove_Occ(s,ch):\n",
      "\t\"\"\"Write a python function to remove first and last occurrence of a given character from the string.\"\"\"\n",
      "\ti = 0\n",
      "\tj = len(s) - 1\n",
      "\twhile i < j:\n",
      "\t\tif s[i] == ch:\n",
      "\t\t\ti += 1\n",
      "\t\telif s[j] == ch:\n",
      "\t\t\tj -= 1\n",
      "\t\telse:\n",
      "\t\t\ti += 1\n",
      "\t\t\tj -= 1\n",
      "\treturn s[i+1:j+1]<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "i = 22\n",
    "new_function = extract_first_function(list_code[i])\n",
    "print(new_function)\n",
    "print(new_function.replace(\"<|endoftext|>\",\"\"))\n",
    "print('============')\n",
    "print(list_code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'endoftext|>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_function[268:].replace(\"<|endoftext|>\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_function_definitions(input_string):\n",
    "    pattern = r\"(def .*?:.*?)(?=^def |\\Z)\"\n",
    "    matches = re.findall(pattern, input_string, re.DOTALL | re.MULTILINE)\n",
    "    return \"\\n\".join(match.strip() for match in matches)\n",
    "\n",
    "\n",
    "def extract_first_function(input_string):\n",
    "    # Regular expression pattern to match Python function\n",
    "    pattern = re.compile(r\"(def .*?:.*?return .*?\\n)(?=\\n|\\Z)\", re.DOTALL)\n",
    "\n",
    "    # Find all matches of the pattern in the input string\n",
    "    matches = pattern.findall(input_string)\n",
    "\n",
    "    # If no complete function is found, return the original string\n",
    "    if not matches:\n",
    "        return input_string\n",
    "\n",
    "    # Return the first complete function\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_function = extract_first_function(list_code[122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def remove_Occ(s,ch):\n",
      "\t\"\"\"Write a python function to remove first and last occurrence of a given character from the string.\"\"\"\n",
      "\ti = 0\n",
      "\tj = len(s)-1\n",
      "\twhile i < j:\n",
      "\t\tif s[i] == ch:\n",
      "\t\t\ti += 1\n",
      "\t\telif s[j] == ch:\n",
      "\t\t\tj -= 1\n",
      "\t\telse:\n",
      "\t\t\ti += 1\n",
      "\t\t\tj -= 1\n",
      "\treturn s[:i] + s[j+1:]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
